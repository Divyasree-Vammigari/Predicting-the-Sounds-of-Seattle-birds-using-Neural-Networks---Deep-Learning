This project aims to classify bird species based on their recorded chirping sounds using the 
Birdcall competition dataset from the Xeno-Canto bird sound archive by leveraging neural 
networks to predict species based on their vocalizations. The study selected 12 bird species and 
developed both a binary classification model for two species and a multi-class classification model 
encompassing all 12 species. The project explored various activation functions and conducted 
extensive hyperparameter tuning to optimize model performance. Additionally, transfer learning 
was employed by adapting a pre-trained neural network model to the specific dataset, enhancing 
the accuracy of the classification tasks. 
The classification models were tested using external raw sound clips, which were converted to 
spectrograms for analysis. Predictions were made using the multi-class model, with justifications 
provided through spectrogram visualizations. Challenges encountered included limited recording 
volumes and difficulty in distinguishing between similar bird calls. Despite these obstacles, the 
neural network demonstrated satisfactory performance. The project underscores the potential of 
neural networks in bioacoustics classification while highlighting areas for improvement, such as 
advanced data augmentation techniques and alternative machine learning models, offering a 
comprehensive evaluation of the research conducted. 
